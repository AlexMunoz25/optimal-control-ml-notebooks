{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2b8c1f8",
   "metadata": {},
   "source": [
    "### A4.2.1. TensorFlow Graph Compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2731eeb",
   "metadata": {},
   "source": [
    "> *`tf.function` traces a Python function into a TensorFlow graph (FuncGraph), which can be optimized by Grappler and optionally compiled by XLA before execution.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc98d9a8",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "TensorFlow's **graph mode** separates graph construction from execution, enabling whole-program optimizations impossible in eager mode.\n",
    "\n",
    "**`tf.function` Mechanics:**\n",
    "\n",
    "1. **Tracing** ‚Äî TF calls the Python function with symbolic `tf.Tensor` placeholders, recording every TF op into a `FuncGraph`.\n",
    "2. **ConcreteFunction** ‚Äî the traced graph + input signature, cached by `(input shapes, input dtypes, Python control flow constants)`.\n",
    "3. **Retracing** ‚Äî triggered by new input signatures. Excessive retracing (many shapes) wastes compilation time.\n",
    "\n",
    "**Graph Optimization (Grappler):**\n",
    "\n",
    "| Pass | Optimization |\n",
    "|------|-------------|\n",
    "| Constant folding | Evaluate ops with compile-time-known inputs |\n",
    "| Common subexpression elimination | Deduplicate identical subgraphs |\n",
    "| Layout optimization | NHWC ‚Üî NCHW for target device |\n",
    "| Op fusion | Merge adjacent ops (e.g., Conv+BN+ReLU) |\n",
    "| Pruning | Remove unreachable ops |\n",
    "\n",
    "**Tracing Pitfalls:**\n",
    "\n",
    "- **Python side effects** in traced functions execute only at trace time, not at call time.\n",
    "- **Python `if/for`** on tensors traces only one branch; use `tf.cond` / `tf.while_loop` for dynamic control flow.\n",
    "- **`input_signature`** on `tf.function` prevents retracing by fixing shapes.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "```python\n",
    "@tf.function(input_signature=[tf.TensorSpec([None, 784], tf.float32)])\n",
    "def predict(x):\n",
    "    return tf.nn.softmax(x @ weights + bias)\n",
    "```\n",
    "\n",
    "`None` in the signature allows variable batch size without retracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77eaa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GraphNode:\n",
    "    op_type: str\n",
    "    name: str\n",
    "    inputs: list[str]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class FuncGraph:\n",
    "    function_name: str\n",
    "    nodes: list[GraphNode] = field(default_factory=list)\n",
    "\n",
    "    def add_node(self, op_type, name, inputs):\n",
    "        node = GraphNode(op_type, name, inputs)\n",
    "        self.nodes.append(node)\n",
    "        return node\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class InputSignature:\n",
    "    shapes: list[tuple]\n",
    "    dtypes: list[str]\n",
    "\n",
    "    @property\n",
    "    def cache_key(self):\n",
    "        return tuple(zip(self.shapes, self.dtypes))\n",
    "\n",
    "\n",
    "graph = FuncGraph(\"predict\")\n",
    "graph.add_node(\"Placeholder\", \"x\", [])\n",
    "graph.add_node(\"ReadVariable\", \"weights\", [])\n",
    "graph.add_node(\"ReadVariable\", \"bias\", [])\n",
    "graph.add_node(\"MatMul\", \"matmul\", [\"x\", \"weights\"])\n",
    "graph.add_node(\"BiasAdd\", \"biasadd\", [\"matmul\", \"bias\"])\n",
    "graph.add_node(\"Softmax\", \"softmax\", [\"biasadd\"])\n",
    "\n",
    "print(f\"FuncGraph: {graph.function_name}\")\n",
    "print(f\"Nodes: {len(graph.nodes)}\")\n",
    "for node in graph.nodes:\n",
    "    inputs_str = f\"({', '.join(node.inputs)})\" if node.inputs else \"()\"\n",
    "    print(f\"  {node.name} = {node.op_type}{inputs_str}\")\n",
    "\n",
    "sig_a = InputSignature(shapes=[(128, 784)], dtypes=[\"float32\"])\n",
    "sig_b = InputSignature(shapes=[(64, 784)], dtypes=[\"float32\"])\n",
    "sig_c = InputSignature(shapes=[(None, 784)], dtypes=[\"float32\"])\n",
    "\n",
    "print(f\"\\nSignature caching:\")\n",
    "print(f\"  batch=128: {sig_a.cache_key}\")\n",
    "print(f\"  batch=64:  {sig_b.cache_key}\")\n",
    "print(f\"  Same key? {sig_a.cache_key == sig_b.cache_key} ‚Üí retrace needed\")\n",
    "print(f\"  With None: {sig_c.cache_key} ‚Üí no retrace for batch changes\")\n",
    "\n",
    "grappler_passes = [\n",
    "    \"constant_folding\",\n",
    "    \"common_subexpression_elimination\",\n",
    "    \"layout_optimization\",\n",
    "    \"op_fusion\",\n",
    "    \"pruning\",\n",
    "]\n",
    "print(f\"\\nGrappler passes: {len(grappler_passes)}\")\n",
    "for pass_name in grappler_passes:\n",
    "    print(f\"  {pass_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4c1a4c",
   "metadata": {},
   "source": [
    "**References:**\n",
    "\n",
    "[üìò TensorFlow. *Introduction to graphs and tf.function.*](https://www.tensorflow.org/guide/intro_to_graphs)\n",
    "\n",
    "[üìò TensorFlow. *Better performance with tf.function.*](https://www.tensorflow.org/guide/function)\n",
    "\n",
    "---\n",
    "\n",
    "[‚¨ÖÔ∏è Previous: JAX Compilation](../01_ML_Compiler_Ecosystem/03_jax_compilation.ipynb) | [Next: JAX Just-in-Time Compilation ‚û°Ô∏è](./02_jax_just_in_time_compilation.ipynb)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
