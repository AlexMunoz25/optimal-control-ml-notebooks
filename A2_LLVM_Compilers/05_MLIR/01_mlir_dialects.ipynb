{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e206895",
   "metadata": {},
   "source": [
    "### A2.5.1. MLIR Dialects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb29a98",
   "metadata": {},
   "source": [
    "> *A dialect in MLIR is a logical grouping of operations, types, and attributes under a namespace, representing a specific level of abstraction or domain.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7000c8e",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "**MLIR** (Multi-Level Intermediate Representation) extends the LLVM philosophy by allowing multiple IRs (dialects) to coexist in one framework, rather than forcing everything into a single flat IR.\n",
    "\n",
    "A **dialect** defines:\n",
    "- **Operations** ‚Äî the instructions of that abstraction level (e.g., `arith.addi`, `linalg.matmul`).\n",
    "- **Types** ‚Äî data representations (e.g., `memref<4x4xf32>`, `tensor<8xf64>`).\n",
    "- **Attributes** ‚Äî compile-time metadata attached to operations.\n",
    "\n",
    "**Key Built-in Dialects:**\n",
    "\n",
    "| Dialect | Purpose | Example Op |\n",
    "|---------|---------|------------|\n",
    "| `arith` | Integer and float arithmetic | `arith.addi`, `arith.mulf` |\n",
    "| `func` | Function definitions and calls | `func.func`, `func.call` |\n",
    "| `memref` | Memory-backed multi-dimensional buffers | `memref.alloc`, `memref.load` |\n",
    "| `tensor` | Value-semantic multi-dimensional data | `tensor.extract`, `tensor.cast` |\n",
    "| `scf` | Structured control flow (for, if, while) | `scf.for`, `scf.if` |\n",
    "| `linalg` | Linear algebra operations on tensors/buffers | `linalg.matmul`, `linalg.generic` |\n",
    "| `affine` | Polyhedral loop/memory analysis | `affine.for`, `affine.load` |\n",
    "| `llvm` | One-to-one mapping to LLVM IR | `llvm.add`, `llvm.call` |\n",
    "\n",
    "**Compilation proceeds by progressively lowering** from high-level dialects (linalg, scf) through mid-level dialects (memref, arith) down to the `llvm` dialect, which maps directly to LLVM IR.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "```mlir\n",
    "func.func @add(%a: f32, %b: f32) -> f32 {\n",
    "  %result = arith.addf %a, %b : f32\n",
    "  return %result : f32\n",
    "}\n",
    "```\n",
    "\n",
    "This function uses two dialects: `func` (for the function structure) and `arith` (for the addition)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf7b55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MLIRType:\n",
    "    name: str\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MLIROperation:\n",
    "    dialect: str\n",
    "    name: str\n",
    "    operand_types: list[MLIRType]\n",
    "    result_type: MLIRType\n",
    "\n",
    "    @property\n",
    "    def qualified_name(self):\n",
    "        return f\"{self.dialect}.{self.name}\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Dialect:\n",
    "    name: str\n",
    "    operations: list[MLIROperation] = field(default_factory=list)\n",
    "    types: list[MLIRType] = field(default_factory=list)\n",
    "\n",
    "    def register_operation(self, op_name, operand_types, result_type):\n",
    "        operation = MLIROperation(self.name, op_name, operand_types, result_type)\n",
    "        self.operations.append(operation)\n",
    "        return operation\n",
    "\n",
    "\n",
    "f32 = MLIRType(\"f32\")\n",
    "i32 = MLIRType(\"i32\")\n",
    "memref_type = MLIRType(\"memref<4x4xf32>\")\n",
    "\n",
    "arith_dialect = Dialect(\"arith\", types=[f32, i32])\n",
    "addf = arith_dialect.register_operation(\"addf\", [f32, f32], f32)\n",
    "muli = arith_dialect.register_operation(\"muli\", [i32, i32], i32)\n",
    "\n",
    "memref_dialect = Dialect(\"memref\", types=[memref_type])\n",
    "alloc = memref_dialect.register_operation(\"alloc\", [], memref_type)\n",
    "load = memref_dialect.register_operation(\"load\", [memref_type, i32], f32)\n",
    "\n",
    "all_dialects = [arith_dialect, memref_dialect]\n",
    "\n",
    "for dialect in all_dialects:\n",
    "    print(f\"Dialect: {dialect.name}\")\n",
    "    print(f\"  Types: {[t.name for t in dialect.types]}\")\n",
    "    for operation in dialect.operations:\n",
    "        operand_names = [t.name for t in operation.operand_types]\n",
    "        print(f\"  Op: {operation.qualified_name}({', '.join(operand_names)}) -> {operation.result_type.name}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdd6a22",
   "metadata": {},
   "source": [
    "**References:**\n",
    "\n",
    "[üìò MLIR Project. *MLIR Language Reference.*](https://mlir.llvm.org/docs/LangRef/)\n",
    "\n",
    "[üìò Lattner, C. et al. (2021). *MLIR: Scaling Compiler Infrastructure for Domain Specific Computation.* IEEE CGO.](https://ieeexplore.ieee.org/document/9370308)\n",
    "\n",
    "---\n",
    "\n",
    "[‚¨ÖÔ∏è Previous: Loop Vectorization](../04_Optimization_Topics/03_loop_vectorization.ipynb) | [Next: Pattern Rewriting ‚û°Ô∏è](./02_pattern_rewriting.ipynb)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
