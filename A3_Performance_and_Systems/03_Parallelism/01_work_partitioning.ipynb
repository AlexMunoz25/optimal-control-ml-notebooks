{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58ec0cf9",
   "metadata": {},
   "source": [
    "### A3.3.1. Work Partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4707042",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Speedup} = \\frac{1}{(1 - p) + \\frac{p}{n}}\n",
    "$$\n",
    "\n",
    "**Amdahl's Law:** where $p$ is the parallelizable fraction and $n$ the number of processors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91ca942",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "**Work partitioning** divides a computation across threads or cores so they execute concurrently. The goal is to minimize total wall-clock time while avoiding synchronization overhead.\n",
    "\n",
    "**Partitioning Strategies:**\n",
    "\n",
    "| Strategy | Description | Use Case |\n",
    "|----------|-------------|----------|\n",
    "| Static (block) | Divide N items into N/P contiguous chunks | Uniform cost per item |\n",
    "| Static (cyclic) | Round-robin assignment | Varying cost, no locality need |\n",
    "| Dynamic | Workers pull from shared queue | Highly variable item cost |\n",
    "| Work-stealing | Idle workers steal from busy workers' queues | Irregular task graphs |\n",
    "\n",
    "**Key Considerations:**\n",
    "\n",
    "- **Load balance** ‚Äî even distribution of work across threads. Imbalance means some threads finish early and idle.\n",
    "- **Granularity** ‚Äî too-fine partitioning wastes time on synchronization; too-coarse limits parallelism.\n",
    "- **Data locality** ‚Äî partitioning should respect cache structure; threads should access nearby memory.\n",
    "- **Amdahl's Law** ‚Äî the serial fraction limits maximum speedup regardless of core count.\n",
    "\n",
    "**Gustafson's Law (Scaled Speedup):**\n",
    "\n",
    "$$\\text{Speedup} = n - \\alpha(n - 1)$$\n",
    "\n",
    "where $\\alpha$ is the serial fraction. As problem size grows with core count, parallel efficiency can remain high.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Summing a 1M-element array across 4 threads: split into 4 chunks of 250K, each thread computes a partial sum, then combine the 4 partial sums (a small serial reduction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81b97f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "\n",
    "SIZE = 10_000_000\n",
    "data = np.random.rand(SIZE)\n",
    "\n",
    "\n",
    "def partial_sum(chunk):\n",
    "    return np.sum(chunk)\n",
    "\n",
    "\n",
    "def parallel_sum(data, num_workers):\n",
    "    chunks = np.array_split(data, num_workers)\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        partial_sums = list(executor.map(partial_sum, chunks))\n",
    "    return sum(partial_sums)\n",
    "\n",
    "\n",
    "serial_result = np.sum(data)\n",
    "\n",
    "worker_counts = [1, 2, 4, 8]\n",
    "print(f\"Array size: {SIZE:,}\")\n",
    "print(f\"Serial sum: {serial_result:.6f}\\n\")\n",
    "\n",
    "for num_workers in worker_counts:\n",
    "    result = parallel_sum(data, num_workers)\n",
    "    chunk_size = SIZE // num_workers\n",
    "    print(f\"Workers: {num_workers}, chunk size: {chunk_size:,}, result: {result:.6f}\")\n",
    "\n",
    "print(\"\\nAmdahl's Law predictions:\")\n",
    "parallel_fractions = [0.50, 0.75, 0.90, 0.95, 0.99]\n",
    "core_counts = [2, 4, 8, 16, 64]\n",
    "\n",
    "header = f\"{'p':>6}\" + \"\".join(f\"{n:>8}\" for n in core_counts)\n",
    "print(header)\n",
    "for parallel_fraction in parallel_fractions:\n",
    "    serial_fraction = 1 - parallel_fraction\n",
    "    speedups = [\n",
    "        1 / (serial_fraction + parallel_fraction / cores)\n",
    "        for cores in core_counts\n",
    "    ]\n",
    "    row = f\"{parallel_fraction:>6.0%}\" + \"\".join(f\"{speedup:>8.2f}\" for speedup in speedups)\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4d85e4",
   "metadata": {},
   "source": [
    "**References:**\n",
    "\n",
    "[üìò Hennessy, J. & Patterson, D. (2019). *Computer Architecture: A Quantitative Approach (6th ed.).* Morgan Kaufmann.](https://www.elsevier.com/books/computer-architecture/hennessy/978-0-12-811905-1)\n",
    "\n",
    "[üìò McCool, M., Reinders, J. & Robison, A. (2012). *Structured Parallel Programming.* Morgan Kaufmann.](https://www.elsevier.com/books/structured-parallel-programming/mccool/978-0-12-415993-8)\n",
    "\n",
    "---\n",
    "\n",
    "[‚¨ÖÔ∏è Previous: Vectorization Reports](../02_Vectorization/02_vectorization_reports.ipynb) | [Next: Lock Contention ‚û°Ô∏è](./02_lock_contention.ipynb)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
