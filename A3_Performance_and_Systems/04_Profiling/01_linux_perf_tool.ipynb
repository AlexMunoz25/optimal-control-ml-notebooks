{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "804f926f",
   "metadata": {},
   "source": [
    "### A3.4.1. Linux perf Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2171ae",
   "metadata": {},
   "source": [
    "> *`perf` is the standard Linux profiling tool that samples hardware performance counters and software events to identify performance bottlenecks with minimal overhead.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce306aca",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "**`perf`** (Linux Performance Events) is a command-line tool that interfaces with the kernel's `perf_event` subsystem to collect hardware and software performance data.\n",
    "\n",
    "**Core Subcommands:**\n",
    "\n",
    "| Command | Purpose |\n",
    "|---------|--------|\n",
    "| `perf stat` | Count events for a command (cycles, instructions, cache misses) |\n",
    "| `perf record` | Sample events and write to `perf.data` |\n",
    "| `perf report` | Analyze `perf.data` ‚Äî show hottest functions |\n",
    "| `perf annotate` | Show source/assembly with per-line event counts |\n",
    "| `perf top` | Live top-like view of hottest functions |\n",
    "| `perf script` | Dump raw samples for custom analysis / flamegraphs |\n",
    "\n",
    "**Common Workflows:**\n",
    "\n",
    "1. **Quick overview:** `perf stat ./program` ‚Äî see IPC, cache misses, branch misses.\n",
    "2. **Hotspot profiling:** `perf record -g ./program` then `perf report` ‚Äî identify hot functions with call graphs.\n",
    "3. **Flamegraph:** `perf script | stackcollapse-perf.pl | flamegraph.pl > out.svg`.\n",
    "4. **Event counting:** `perf stat -e cache-misses,cache-references ./program` ‚Äî ratio gives miss rate.\n",
    "\n",
    "**Key Metrics from `perf stat`:**\n",
    "\n",
    "- **IPC (Instructions Per Cycle)** ‚Äî higher is better; ‚â•2 is good for modern CPUs.\n",
    "- **Cache miss rate** ‚Äî `cache-misses / cache-references`.\n",
    "- **Branch miss rate** ‚Äî `branch-misses / branches`.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "```bash\n",
    "$ perf stat -e cycles,instructions,cache-misses,branch-misses ./matrix_multiply\n",
    "\n",
    " 3,200,000,000  cycles\n",
    " 8,500,000,000  instructions  #  2.66 IPC\n",
    "     1,200,000  cache-misses  #  0.12% of cache refs\n",
    "       450,000  branch-misses #  0.03% of branches\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b74026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PerfStatResult:\n",
    "    cycles: int\n",
    "    instructions: int\n",
    "    cache_references: int\n",
    "    cache_misses: int\n",
    "    branches: int\n",
    "    branch_misses: int\n",
    "    wall_time_seconds: float\n",
    "\n",
    "    @property\n",
    "    def ipc(self):\n",
    "        return self.instructions / self.cycles\n",
    "\n",
    "    @property\n",
    "    def cache_miss_rate(self):\n",
    "        return self.cache_misses / self.cache_references\n",
    "\n",
    "    @property\n",
    "    def branch_miss_rate(self):\n",
    "        return self.branch_misses / self.branches\n",
    "\n",
    "\n",
    "def display_perf_stat(label, result):\n",
    "    print(f\"{label}:\")\n",
    "    print(f\"  {result.cycles:>15,}  cycles\")\n",
    "    print(f\"  {result.instructions:>15,}  instructions  # {result.ipc:.2f} IPC\")\n",
    "    print(f\"  {result.cache_misses:>15,}  cache-misses  # {result.cache_miss_rate:.2%} of cache refs\")\n",
    "    print(f\"  {result.branch_misses:>15,}  branch-misses # {result.branch_miss_rate:.2%} of branches\")\n",
    "    print(f\"  {result.wall_time_seconds:>15.4f}  seconds time elapsed\")\n",
    "    print()\n",
    "\n",
    "\n",
    "optimized_run = PerfStatResult(\n",
    "    cycles=3_200_000_000,\n",
    "    instructions=8_500_000_000,\n",
    "    cache_references=1_000_000_000,\n",
    "    cache_misses=1_200_000,\n",
    "    branches=1_500_000_000,\n",
    "    branch_misses=450_000,\n",
    "    wall_time_seconds=1.07,\n",
    ")\n",
    "\n",
    "unoptimized_run = PerfStatResult(\n",
    "    cycles=12_800_000_000,\n",
    "    instructions=6_000_000_000,\n",
    "    cache_references=2_000_000_000,\n",
    "    cache_misses=800_000_000,\n",
    "    branches=1_500_000_000,\n",
    "    branch_misses=150_000_000,\n",
    "    wall_time_seconds=4.27,\n",
    ")\n",
    "\n",
    "display_perf_stat(\"Optimized (tiled matrix multiply)\", optimized_run)\n",
    "display_perf_stat(\"Unoptimized (naive column-major)\", unoptimized_run)\n",
    "\n",
    "print(\"Comparison:\")\n",
    "print(f\"  IPC improvement: {optimized_run.ipc:.2f} vs {unoptimized_run.ipc:.2f}\")\n",
    "print(f\"  Cache miss reduction: {unoptimized_run.cache_miss_rate:.2%} ‚Üí {optimized_run.cache_miss_rate:.2%}\")\n",
    "print(f\"  Speedup: {unoptimized_run.wall_time_seconds / optimized_run.wall_time_seconds:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0d2b3c",
   "metadata": {},
   "source": [
    "**References:**\n",
    "\n",
    "[üìò Gregg, B. (2020). *Systems Performance: Enterprise and the Cloud (2nd ed.).* Addison-Wesley.](https://www.brendangregg.com/systems-performance-2nd-edition-book.html)\n",
    "\n",
    "[üìò Linux Kernel Documentation. *perf ‚Äî Linux profiling with performance counters.*](https://perf.wiki.kernel.org/index.php/Main_Page)\n",
    "\n",
    "---\n",
    "\n",
    "[‚¨ÖÔ∏è Previous: Lock Contention](../03_Parallelism/02_lock_contention.ipynb) | [Next: Hardware Performance Counters ‚û°Ô∏è](./02_hardware_performance_counters.ipynb)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
